{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA WRANGLING REPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Gathering:\n",
    "This project __WE RATE DOGS__ involved 3 data sources:\n",
    "> * An already enhaced Twitter Archive Data of the [weratedogs](twitter.com/) twitter account, __twitter_archive_enhanced.csv__ provided already.\n",
    "\n",
    "> * An image prediction file of each of the pictures of dogs contained in the tweets __image_predictions.tsv__ this was downloaded programmatically, using the __request library__\n",
    "\n",
    "> * Additional Data on the tweets in the Twitter Archive Data, this was scraped using Tweepy, I couldn't get access to twitter API so I used the already provided file from Udacity, the code for accessing the data with __Tweepy__ is provided in the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the Data:\n",
    "The data was assessed visually and programatically.\n",
    "It was assessed visually with __Atom__ and programatically with __Pandas__\n",
    "\n",
    "I assessed the data using the common pandas dataframe methods, `.info(), .isna(), .describe() ` etc\n",
    "\n",
    "> * 8 Quality issues was identified.\n",
    "> * 3 Tidiness issues were identified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Data:\n",
    "\n",
    "All quality and tidiness issues that were identified were cleaned in outlined steps. using the...\n",
    "> * Define\n",
    "> * Code \n",
    "> * Test\n",
    "\n",
    "...model. \n",
    "\n",
    "#### Quality Issue 1: Tweet id are integers instead of strings\n",
    "> I converted the different id columns of the 3 different datasets to str using the `.astype(str)` function\n",
    "\n",
    "#### Quality Issue 2: set id as the index in the datasets\n",
    "> I converted the different id columns of the 3 datasets to the index of each dataset using `df.set_index()` since they're serve as unique identifiers. \n",
    "\n",
    "#### Quality Issue 3: Replies to tweets should be dropped\n",
    "> Since the focus of the project is in original ratings and not __replies__, the replies were dropped by subsetting only those tweets that aren't __replies__.\n",
    "\n",
    "#### Quality Issue 4: Retweets should be dropped\n",
    "> Since the focus of the project is in original ratings and not replies nor __retweets__, the retweets were dropped by subsetting only those tweets that aren't __retweets__.\n",
    "\n",
    "#### Quality Issue 5: Ratings of dogs have values of zero\n",
    "> For a community that are used to rating dogs above 10, defying the law of proportions, ratings with values of zero were dropped.\n",
    "\n",
    "#### Quality Issue 6: Ratings of dogs with a denominator greater than 10\n",
    "> Dogs were being rated out of 10, denominators with numbers above or below 10 were replaced with 10 as this is standard.\n",
    "\n",
    "#### Quality Issue 7: Configuration accuracy in the Image Predictions dataset should be in percentage. \n",
    "> For easy readability, the performance of the algorithm in predicting the type of dog in the pictures were converted to percentages by multiplying its values by 100 and rounded to 2 decimal places.\n",
    "`(image_prediction_copy.p1_conf*100).round(2)`\n",
    "\n",
    "#### Quality Issue 8: Extraneous columns in the datasets\n",
    "> Columns which were not necessary for analysis were dropped from the 3 datasets\n",
    "\n",
    "#### Tidiness Issue 1: Rating denominator and numerator should be in one column\n",
    "> One of the rules of tidiness is that one column represents one variable, here, a single variable is split in __2 columns.__\n",
    "\n",
    "#### Tidiness Issue 2: Dog stages are in different columns\n",
    "> One of the rules of tidiness is that one column represents one variable, here, a single variable is split in __4 columns__\n",
    "I used the `pd.melt()` function to convert them all to one column\n",
    "\n",
    "#### Tidiness Issue 3: The 3 datasets should be merged into one dataset\n",
    "> One of the rules of tidiness is that Each type of observational unit forms a table. I joined the 3 datasets to one master dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
